{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The objective of the project is to learn how to implement a simple image classification pipeline based on the k-Nearest Neighbour and a deep neural network. The goals of this assignment are as follows:\n",
    "\n",
    "● Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages)\n",
    "\n",
    "● Data fetching and understand the train/val/test splits.\n",
    "\n",
    "● Implement and apply an optimal k-Nearest Neighbor (kNN) classifier (7.5 points)\n",
    "\n",
    "● Print the classification metric report (2.5 points)\n",
    "\n",
    "● Implement and apply a deep neural network classifier including (feedforward neural network, RELU activations) (5 points)\n",
    "\n",
    "● Understand and be able to implement (vectorized) backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions) (2.5 points)\n",
    "\n",
    "● Implement batch normalization for training the neural network (2.5 points)\n",
    "\n",
    "● Understand the differences and trade-offs between traditional and NN classifiers with the help of classification metrics (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras as ks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import h5py\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = h5py.File('SVHN_single_grey1.h5','r+') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>\n"
     ]
    }
   ],
   "source": [
    "# List all groups\n",
    "print(\"Keys: %s\" % img_df.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_text = img_df['X_test']\n",
    "x_train = img_df['X_train']\n",
    "x_val = img_df['X_val']\n",
    "y_test = img_df['y_test']\n",
    "y_train = img_df['y_train']\n",
    "y_val = img_df['y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 32, 32)\n",
      "(42000, 32, 32)\n",
      "(60000, 32, 32)\n",
      "(18000,)\n",
      "(42000,)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print (x_text.shape)\n",
    "print (x_train.shape)\n",
    "print (x_val.shape)\n",
    "print (y_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Implement and apply an optimal k-Nearest Neighbor (kNN) classifier (7.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KNN Classifier\n",
    "model_knn = KNeighborsClassifier(n_neighbors=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening the data\n",
    "X_train = np.reshape(x_train,(42000,32*32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=17, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dimension from 3D to 2D and predict\n",
    "X_text = np.reshape(x_text,(18000,32*32))\n",
    "prediction = model_knn.predict(X_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the classification metric report (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5287222222222222\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Metrix:   \n",
      " [[1274   99   94  129  105  165  319  100  247  323]\n",
      " [  66 1335  226  260  249  172  128  209  119  142]\n",
      " [  34   55 1000  135   41   47   40  110   68   71]\n",
      " [  35   95   95  736   60  269   67   88  114   89]\n",
      " [  46   69   44   47 1177   58  135   27   94   71]\n",
      " [  45   36   37  160   16  693  116   37  115   93]\n",
      " [  98   31   35   36   54  137  744   37  265   55]\n",
      " [  39   46  141   57   19   31   21 1128   25   73]\n",
      " [  78   26   52   94   43  119  202   24  654  111]\n",
      " [  99   36   79   65   48   77   60   48  111  776]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Metrix:   \\n\", metrics.confusion_matrix(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.70      0.55      1814\n",
      "           1       0.46      0.73      0.56      1828\n",
      "           2       0.62      0.55      0.59      1803\n",
      "           3       0.45      0.43      0.44      1719\n",
      "           4       0.67      0.65      0.66      1812\n",
      "           5       0.51      0.39      0.44      1768\n",
      "           6       0.50      0.41      0.45      1832\n",
      "           7       0.71      0.62      0.67      1808\n",
      "           8       0.47      0.36      0.41      1812\n",
      "           9       0.55      0.43      0.48      1804\n",
      "\n",
      "   micro avg       0.53      0.53      0.53     18000\n",
      "   macro avg       0.54      0.53      0.52     18000\n",
      "weighted avg       0.54      0.53      0.52     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = metrics.classification_report(y_test,prediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement and apply a deep neural network classifier including (feedforward neural network, RELU activations) (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model_nn = ks.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape data from 2D to 1D -> 32X32 to 1024\n",
    "model_nn.add(ks.layers.Reshape((1024,),input_shape=(32,32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement batch normalization for training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "model_nn.add(ks.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.add(ks.layers.Dense(150, activation='relu'))\n",
    "model_nn.add(ks.layers.Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output layer\n",
    "model_nn.add(ks.layers.Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand and be able to implement (vectorized) backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions) (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change train and test labels into one-hot vectors\n",
    "trainY = ks.utils.to_categorical(y_train, num_classes=10)\n",
    "testY = ks.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\msrikanta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/75\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 2.1719 - acc: 0.2299 - val_loss: 1.9331 - val_acc: 0.3748\n",
      "Epoch 2/75\n",
      "42000/42000 [==============================] - 2s 59us/step - loss: 1.7271 - acc: 0.4634 - val_loss: 1.5270 - val_acc: 0.5457\n",
      "Epoch 3/75\n",
      "42000/42000 [==============================] - 3s 61us/step - loss: 1.4048 - acc: 0.5872 - val_loss: 1.2812 - val_acc: 0.6288\n",
      "Epoch 4/75\n",
      "42000/42000 [==============================] - 3s 64us/step - loss: 1.2164 - acc: 0.6481 - val_loss: 1.1366 - val_acc: 0.6743\n",
      "Epoch 5/75\n",
      "42000/42000 [==============================] - 3s 64us/step - loss: 1.1000 - acc: 0.6803 - val_loss: 1.0456 - val_acc: 0.6976\n",
      "Epoch 6/75\n",
      "42000/42000 [==============================] - 3s 63us/step - loss: 1.0191 - acc: 0.7037 - val_loss: 0.9874 - val_acc: 0.7133\n",
      "Epoch 7/75\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.9586 - acc: 0.7195 - val_loss: 0.9373 - val_acc: 0.7277\n",
      "Epoch 8/75\n",
      "42000/42000 [==============================] - 3s 74us/step - loss: 0.9087 - acc: 0.7324 - val_loss: 0.9013 - val_acc: 0.7352\n",
      "Epoch 9/75\n",
      "42000/42000 [==============================] - 3s 73us/step - loss: 0.8660 - acc: 0.7454 - val_loss: 0.8678 - val_acc: 0.7474\n",
      "Epoch 10/75\n",
      "42000/42000 [==============================] - 3s 75us/step - loss: 0.8296 - acc: 0.7556 - val_loss: 0.8512 - val_acc: 0.7507\n",
      "Epoch 11/75\n",
      "42000/42000 [==============================] - 3s 74us/step - loss: 0.7970 - acc: 0.7659 - val_loss: 0.8179 - val_acc: 0.7587\n",
      "Epoch 12/75\n",
      "42000/42000 [==============================] - 3s 74us/step - loss: 0.7685 - acc: 0.7726 - val_loss: 0.8030 - val_acc: 0.7633\n",
      "Epoch 13/75\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 0.7415 - acc: 0.7816 - val_loss: 0.7760 - val_acc: 0.7777\n",
      "Epoch 14/75\n",
      "42000/42000 [==============================] - 3s 74us/step - loss: 0.7171 - acc: 0.7887 - val_loss: 0.7684 - val_acc: 0.7779\n",
      "Epoch 15/75\n",
      "42000/42000 [==============================] - 3s 74us/step - loss: 0.6954 - acc: 0.7962 - val_loss: 0.7495 - val_acc: 0.7810\n",
      "Epoch 16/75\n",
      "42000/42000 [==============================] - 3s 75us/step - loss: 0.6760 - acc: 0.8001 - val_loss: 0.7278 - val_acc: 0.7901\n",
      "Epoch 17/75\n",
      "42000/42000 [==============================] - 3s 75us/step - loss: 0.6555 - acc: 0.8069 - val_loss: 0.7216 - val_acc: 0.7921\n",
      "Epoch 18/75\n",
      "42000/42000 [==============================] - 3s 75us/step - loss: 0.6392 - acc: 0.8113 - val_loss: 0.7090 - val_acc: 0.7967\n",
      "Epoch 19/75\n",
      "42000/42000 [==============================] - 3s 75us/step - loss: 0.6232 - acc: 0.8161 - val_loss: 0.6994 - val_acc: 0.7994\n",
      "Epoch 20/75\n",
      "42000/42000 [==============================] - 3s 75us/step - loss: 0.6083 - acc: 0.8215 - val_loss: 0.6824 - val_acc: 0.8070\n",
      "Epoch 21/75\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 0.5950 - acc: 0.8255 - val_loss: 0.6826 - val_acc: 0.8054\n",
      "Epoch 22/75\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 0.5813 - acc: 0.8290 - val_loss: 0.6688 - val_acc: 0.8112\n",
      "Epoch 23/75\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 0.5691 - acc: 0.8324 - val_loss: 0.6663 - val_acc: 0.8110\n",
      "Epoch 24/75\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 0.5581 - acc: 0.8362 - val_loss: 0.6638 - val_acc: 0.8089\n",
      "Epoch 25/75\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 0.5470 - acc: 0.8381 - val_loss: 0.6479 - val_acc: 0.8166\n",
      "Epoch 26/75\n",
      "42000/42000 [==============================] - 3s 77us/step - loss: 0.5367 - acc: 0.8411 - val_loss: 0.6438 - val_acc: 0.8193\n",
      "Epoch 27/75\n",
      "42000/42000 [==============================] - 3s 77us/step - loss: 0.5271 - acc: 0.8444 - val_loss: 0.6428 - val_acc: 0.8193\n",
      "Epoch 28/75\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 0.5165 - acc: 0.8472 - val_loss: 0.6371 - val_acc: 0.8202\n",
      "Epoch 29/75\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 0.5094 - acc: 0.8498 - val_loss: 0.6376 - val_acc: 0.8216\n",
      "Epoch 30/75\n",
      "42000/42000 [==============================] - 4s 85us/step - loss: 0.5001 - acc: 0.8525 - val_loss: 0.6258 - val_acc: 0.8253\n",
      "Epoch 31/75\n",
      "42000/42000 [==============================] - 4s 88us/step - loss: 0.4915 - acc: 0.8552 - val_loss: 0.6268 - val_acc: 0.8231\n",
      "Epoch 32/75\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.4838 - acc: 0.8570 - val_loss: 0.6213 - val_acc: 0.8243\n",
      "Epoch 33/75\n",
      "42000/42000 [==============================] - 4s 92us/step - loss: 0.4781 - acc: 0.8586 - val_loss: 0.6195 - val_acc: 0.8266\n",
      "Epoch 34/75\n",
      "42000/42000 [==============================] - 4s 100us/step - loss: 0.4699 - acc: 0.8608 - val_loss: 0.6116 - val_acc: 0.8288\n",
      "Epoch 35/75\n",
      "42000/42000 [==============================] - 4s 99us/step - loss: 0.4632 - acc: 0.8638 - val_loss: 0.6123 - val_acc: 0.8286\n",
      "Epoch 36/75\n",
      "42000/42000 [==============================] - 4s 99us/step - loss: 0.4553 - acc: 0.8659 - val_loss: 0.6098 - val_acc: 0.8286\n",
      "Epoch 37/75\n",
      "42000/42000 [==============================] - 4s 86us/step - loss: 0.4490 - acc: 0.8678 - val_loss: 0.6207 - val_acc: 0.8254\n",
      "Epoch 38/75\n",
      "42000/42000 [==============================] - 4s 93us/step - loss: 0.4439 - acc: 0.8683 - val_loss: 0.5994 - val_acc: 0.8339\n",
      "Epoch 39/75\n",
      "42000/42000 [==============================] - 4s 92us/step - loss: 0.4384 - acc: 0.8698 - val_loss: 0.5935 - val_acc: 0.8356-\n",
      "Epoch 40/75\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.4314 - acc: 0.8724 - val_loss: 0.5990 - val_acc: 0.8299\n",
      "Epoch 41/75\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.4262 - acc: 0.8738 - val_loss: 0.5962 - val_acc: 0.8353\n",
      "Epoch 42/75\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 0.4226 - acc: 0.8740 - val_loss: 0.5962 - val_acc: 0.8363\n",
      "Epoch 43/75\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.4161 - acc: 0.8770 - val_loss: 0.6021 - val_acc: 0.8332\n",
      "Epoch 44/75\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.4125 - acc: 0.8769 - val_loss: 0.5998 - val_acc: 0.8338\n",
      "Epoch 45/75\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.4049 - acc: 0.8800 - val_loss: 0.5852 - val_acc: 0.8377\n",
      "Epoch 46/75\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4018 - acc: 0.8801 - val_loss: 0.5874 - val_acc: 0.8359\n",
      "Epoch 47/75\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 0.3962 - acc: 0.8822 - val_loss: 0.5927 - val_acc: 0.8338\n",
      "Epoch 48/75\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 0.3933 - acc: 0.8828 - val_loss: 0.6008 - val_acc: 0.8339\n",
      "Epoch 49/75\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.3870 - acc: 0.8846 - val_loss: 0.5799 - val_acc: 0.8383\n",
      "Epoch 50/75\n",
      "42000/42000 [==============================] - 4s 86us/step - loss: 0.3849 - acc: 0.8861 - val_loss: 0.5885 - val_acc: 0.8357\n",
      "Epoch 51/75\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 0.3783 - acc: 0.8883 - val_loss: 0.5886 - val_acc: 0.8364\n",
      "Epoch 52/75\n",
      "42000/42000 [==============================] - 4s 85us/step - loss: 0.3755 - acc: 0.8886 - val_loss: 0.5909 - val_acc: 0.8363\n",
      "Epoch 53/75\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 0.3715 - acc: 0.8892 - val_loss: 0.5877 - val_acc: 0.8382\n",
      "Epoch 54/75\n",
      "42000/42000 [==============================] - 4s 90us/step - loss: 0.3680 - acc: 0.8903 - val_loss: 0.5778 - val_acc: 0.8404\n",
      "Epoch 55/75\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 0.3631 - acc: 0.8928 - val_loss: 0.5876 - val_acc: 0.8361\n",
      "Epoch 56/75\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.3587 - acc: 0.8953 - val_loss: 0.5769 - val_acc: 0.8419\n",
      "Epoch 57/75\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.3549 - acc: 0.8945 - val_loss: 0.5802 - val_acc: 0.8425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/75\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 0.3534 - acc: 0.8952 - val_loss: 0.5894 - val_acc: 0.8388\n",
      "Epoch 59/75\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.3469 - acc: 0.8966 - val_loss: 0.5962 - val_acc: 0.8352\n",
      "Epoch 60/75\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.3453 - acc: 0.8975 - val_loss: 0.5834 - val_acc: 0.8407\n",
      "Epoch 61/75\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 0.3403 - acc: 0.8981 - val_loss: 0.5816 - val_acc: 0.8413\n",
      "Epoch 62/75\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.3369 - acc: 0.9010 - val_loss: 0.5944 - val_acc: 0.8385\n",
      "Epoch 63/75\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3344 - acc: 0.9000 - val_loss: 0.5842 - val_acc: 0.8412\n",
      "Epoch 64/75\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.3314 - acc: 0.9016 - val_loss: 0.5818 - val_acc: 0.8417\n",
      "Epoch 65/75\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.3284 - acc: 0.9031 - val_loss: 0.5865 - val_acc: 0.8425\n",
      "Epoch 66/75\n",
      "42000/42000 [==============================] - 4s 88us/step - loss: 0.3255 - acc: 0.9045 - val_loss: 0.6028 - val_acc: 0.8362\n",
      "Epoch 67/75\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.3221 - acc: 0.9043 - val_loss: 0.5781 - val_acc: 0.8442\n",
      "Epoch 68/75\n",
      "42000/42000 [==============================] - 4s 86us/step - loss: 0.3175 - acc: 0.9063 - val_loss: 0.5881 - val_acc: 0.8424\n",
      "Epoch 69/75\n",
      "42000/42000 [==============================] - 4s 85us/step - loss: 0.3186 - acc: 0.9054 - val_loss: 0.5903 - val_acc: 0.8421\n",
      "Epoch 70/75\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 0.3139 - acc: 0.9071 - val_loss: 0.6169 - val_acc: 0.8354\n",
      "Epoch 71/75\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 0.3121 - acc: 0.9070 - val_loss: 0.5885 - val_acc: 0.8420\n",
      "Epoch 72/75\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3094 - acc: 0.9093 - val_loss: 0.5888 - val_acc: 0.8416\n",
      "Epoch 73/75\n",
      "42000/42000 [==============================] - 4s 90us/step - loss: 0.3058 - acc: 0.9089 - val_loss: 0.5843 - val_acc: 0.8443\n",
      "Epoch 74/75\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.3034 - acc: 0.9110 - val_loss: 0.6041 - val_acc: 0.8393\n",
      "Epoch 75/75\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 0.2995 - acc: 0.9113 - val_loss: 0.5984 - val_acc: 0.8419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bdce153ef0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "features_val_arr = np.array(x_text)\n",
    "model_nn.fit(x_train,trainY,          \n",
    "          validation_data=(features_val_arr, testY),\n",
    "          epochs=75,\n",
    "          batch_size=150,validation_split = 0.01,\n",
    "         shuffle='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 66us/step\n",
      "[0.5984484396908019, 0.8418888888888889]\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "evaluate = model_nn.evaluate(x_text, testY)\n",
    "print(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model\n",
    "y_predict=model_nn.predict_classes(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      1814\n",
      "           1       0.83      0.86      0.85      1828\n",
      "           2       0.87      0.85      0.86      1803\n",
      "           3       0.80      0.78      0.79      1719\n",
      "           4       0.88      0.87      0.88      1812\n",
      "           5       0.81      0.83      0.82      1768\n",
      "           6       0.84      0.83      0.83      1832\n",
      "           7       0.89      0.87      0.88      1808\n",
      "           8       0.81      0.81      0.81      1812\n",
      "           9       0.84      0.83      0.83      1804\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     18000\n",
      "   macro avg       0.84      0.84      0.84     18000\n",
      "weighted avg       0.84      0.84      0.84     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr=metrics.classification_report(y_test,y_predict)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand the differences and trade-offs between traditional and NN classifiers with the help of classification metrics (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### KNN does not perform well compared to DNN\n",
    " \n",
    "KNN: \n",
    "\n",
    "Accuracy - 52.87%\n",
    "\n",
    "Precision - 54%\n",
    "\n",
    "Recall - 53% \n",
    "\n",
    "F1 Score - 52%\n",
    "\n",
    "\n",
    "DNN:\n",
    "\n",
    "Accuracy - 84.18%\n",
    "\n",
    "Precision - 84%\n",
    "\n",
    "Recall - 84% \n",
    "\n",
    "F1 Score - 84%\n",
    "\n",
    "It is clear from the above that DNN performs better than KNN. Neural network the hidden layers learn the image features by adjusting the weights and is able to classify better than KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
